{
  "react_negative": {
    "precision": 0.9148936170212766,
    "recall": 0.9148936170212766,
    "f1-score": 0.9148936170212766,
    "support": 47,
    "confused_with": {
      "mood_unhappy": 4
    }
  },
  "inform_location": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 24,
    "confused_with": {}
  },
  "out_of_scope": {
    "precision": 0.9975961538461539,
    "recall": 0.9952038369304557,
    "f1-score": 0.9963985594237696,
    "support": 417,
    "confused_with": {
      "chitchat": 2
    }
  },
  "inform_employee_type": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 31,
    "confused_with": {}
  },
  "how_to_get_started": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 372,
    "confused_with": {}
  },
  "human_handoff": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 66,
    "confused_with": {}
  },
  "need_help_broad": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 15,
    "confused_with": {}
  },
  "bye": {
    "precision": 0.9767441860465116,
    "recall": 1.0,
    "f1-score": 0.988235294117647,
    "support": 42,
    "confused_with": {}
  },
  "inform_country": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 9,
    "confused_with": {}
  },
  "query_top_accidents": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4,
    "confused_with": {}
  },
  "inform_gender": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2,
    "confused_with": {}
  },
  "affirm": {
    "precision": 0.9911504424778761,
    "recall": 0.9955555555555555,
    "f1-score": 0.9933481152993349,
    "support": 225,
    "confused_with": {
      "mood_great": 1
    }
  },
  "inform_industry_type": {
    "precision": 0.875,
    "recall": 1.0,
    "f1-score": 0.9333333333333333,
    "support": 7,
    "confused_with": {}
  },
  "react_positive": {
    "precision": 0.9838709677419355,
    "recall": 1.0,
    "f1-score": 0.991869918699187,
    "support": 61,
    "confused_with": {}
  },
  "chitchat": {
    "precision": 0.9972451790633609,
    "recall": 0.9986206896551724,
    "f1-score": 0.997932460372157,
    "support": 725,
    "confused_with": {
      "react_positive": 1
    }
  },
  "greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 141,
    "confused_with": {}
  },
  "canthelp": {
    "precision": 1.0,
    "recall": 0.9615384615384616,
    "f1-score": 0.9803921568627451,
    "support": 26,
    "confused_with": {
      "bye": 1
    }
  },
  "explain": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 16,
    "confused_with": {}
  },
  "inform_accident_level": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 18,
    "confused_with": {}
  },
  "next_step": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 15,
    "confused_with": {}
  },
  "deny": {
    "precision": 1.0,
    "recall": 0.99,
    "f1-score": 0.9949748743718593,
    "support": 100,
    "confused_with": {
      "out_of_scope": 1
    }
  },
  "mood_unhappy": {
    "precision": 0.7142857142857143,
    "recall": 0.7142857142857143,
    "f1-score": 0.7142857142857143,
    "support": 14,
    "confused_with": {
      "react_negative": 4
    }
  },
  "restart": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "thank": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 39,
    "confused_with": {}
  },
  "inform_critical_risk": {
    "precision": 1.0,
    "recall": 0.96875,
    "f1-score": 0.9841269841269841,
    "support": 32,
    "confused_with": {
      "inform_industry_type": 1
    }
  },
  "mood_great": {
    "precision": 0.95,
    "recall": 0.9047619047619048,
    "f1-score": 0.9268292682926829,
    "support": 21,
    "confused_with": {
      "affirm": 2
    }
  },
  "accuracy": 0.9931423961274708,
  "macro avg": {
    "precision": 0.976953317710878,
    "recall": 0.9786003761441747,
    "f1-score": 0.9775623190848726,
    "support": 2479
  },
  "weighted avg": {
    "precision": 0.9931922490433709,
    "recall": 0.9931423961274708,
    "f1-score": 0.9931379594032387,
    "support": 2479
  }
}